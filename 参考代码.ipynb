{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "参考代码.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "PScUVz69c7s5",
        "dzovoIq4Pf-l",
        "pBbdysRRShPk"
      ],
      "toc_visible": true,
      "mount_file_id": "1GTFEHaQY4E92hygbZgqMwMnFARLdLhuk",
      "authorship_tag": "ABX9TyMljFY9cq3S7lxICYGIK2iu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zifeiYv/BiLSTM-CRF/blob/master/%E5%8F%82%E8%80%83%E4%BB%A3%E7%A0%81.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1、Imports"
      ],
      "metadata": {
        "id": "thBtBjpwbuGz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "refs: https://www.kaggle.com/code/dimitriosroussis/electricity-price-forecasting-with-dnns-eda/notebook"
      ],
      "metadata": {
        "id": "d8eRhNaADgrh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import deque\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import xgboost as xgb\n",
        "import statsmodels.api as sm\n",
        "import seaborn as sns\n",
        "\n",
        "from tqdm import tqdm\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_percentage_error\n",
        "from statsmodels.tsa.stattools import adfuller, kpss, ccf\n",
        "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf"
      ],
      "metadata": {
        "id": "VgM7WiGhD4bC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_df = pd.read_csv('/content/drive/MyDrive/风行数据/all_df.csv', parse_dates=['时间戳'])"
      ],
      "metadata": {
        "id": "Lvilx6cDEdvY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2、数据探索"
      ],
      "metadata": {
        "id": "PScUVz69c7s5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 价格与周平均价格趋势变化图\n",
        "rolling = all_df['统一出清价格-日前(元/MWh)'].rolling(96*7, center=True).mean()\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(30, 12))\n",
        "ax.set_xlabel('Time', fontsize=16)\n",
        "ax.plot(all_df['时间戳'], all_df['统一出清价格-日前(元/MWh)'], label='real time price')\n",
        "ax.plot(all_df['时间戳'], rolling, label='week mean price', linestyle='-', linewidth=2)\n",
        "\n",
        "ax.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "nSntdIQDdApu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 价格滞后（一日）比率图\n",
        "change = all_df['统一出清价格-日前(元/MWh)'].div(all_df['统一出清价格-日前(元/MWh)'].shift(96)).mul(100)\n",
        "fig, ax = plt.subplots(figsize=(30, 12))\n",
        "ax.plot(change[:96*7])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "-hBBvWXCjfTr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 价格分布直方图\n",
        "all_df['统一出清价格-日前(元/MWh)'].plot.hist(bins=18, alpha=0.65)"
      ],
      "metadata": {
        "id": "FfrJV5mAm7Eo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 价格的季节分解图\n",
        "res = sm.tsa.seasonal_decompose(all_df['统一出清价格-日前(元/MWh)'], model='additive', freq=4*24)\n",
        "\n",
        "fig, (ax1, ax2, ax3, ax4) = plt.subplots(4, 1, figsize=(20, 12))\n",
        "res.observed.plot(ax=ax1, title='Observed')\n",
        "res.trend.plot(ax=ax2, title='Trend')\n",
        "res.resid.plot(ax=ax3, title='Residual')\n",
        "res.seasonal.plot(ax=ax4, title='Seasonal')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Okrx9EdynJmv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 对价格进行ADF检验\n",
        "# 原假设：时间序列是非平稳的，存在单位根\n",
        "# 备择假设：时间序列是平稳的\n",
        "# \n",
        "adf_test = adfuller(all_df['统一出清价格-日前(元/MWh)'], regression='c')\n",
        "print('ADF Statistic: {:.6f}\\np-value: {:.6f}\\n#Lags used: {}'\n",
        "      .format(adf_test[0], adf_test[1], adf_test[2]))\n",
        "for key, value in adf_test[4].items():\n",
        "    print('Critical Value ({}): {:.6f}'.format(key, value))\n",
        "# 检验统计量的值小于1%水平下的临界值，说明有99%的把握拒绝原假设，即价格序列可以认为是平稳的"
      ],
      "metadata": {
        "id": "xVHlsVeMpVkJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 对价格进行KPSS检验\n",
        "# 原假设：时间序列在一个常数附近是平稳的\n",
        "# 备择假设：时间序列存在一个单位根，即，是不平稳的\n",
        "kpss_test = kpss(all_df['统一出清价格-日前(元/MWh)'], regression='c', lags='legacy')\n",
        "print('KPSS Statistic: {:.6f}\\np-value: {:.6f}\\n#Lags used: {}'\n",
        "      .format(kpss_test[0], kpss_test[1], kpss_test[2]))\n",
        "for key, value in kpss_test[3].items():\n",
        "    print('Critical Value ({}): {:.6f}'.format(key, value))\n",
        "# 检验统计量的值大于1%水平下的临界值，说明在此种情况下无法拒绝原假设，即价格序列可以认为是平稳的"
      ],
      "metadata": {
        "id": "SAUdPT1utOmq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 绘制自相关与偏自相关图\n",
        "fig, (ax1, ax2) = plt.subplots(nrows=2, figsize=(10, 6))\n",
        "plot_acf(all_df['统一出清价格-日前(元/MWh)'], lags=200, ax=ax1)\n",
        "plot_pacf(all_df['统一出清价格-日前(元/MWh)'], lags=50, ax=ax2)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "XrNrWbC0ufYf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 相关性矩阵（皮尔森相关系数）\n",
        "correlations = all_df.corr(method='pearson')\n",
        "fig = plt.figure(figsize=(24, 24))\n",
        "sns.heatmap(correlations, annot=True, fmt='.2f')\n",
        "plt.title('Pearson Correlation Matrix')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "HGieulho5nMR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3、特征工程"
      ],
      "metadata": {
        "id": "oaj0WSWiZHPu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "is_peak = []  # 是否用电高峰\n",
        "hours = []  # 当前时间戳的所属小时\n",
        "weekdays = []  # 当前日期是周几\n",
        "months = []  # 当前日期所属的月份\n",
        "is_weekend = []  # 当前是否为周末\n",
        "\n",
        "for i in range(len(all_df)):\n",
        "    timestamp = all_df['时间戳'].iloc[i]\n",
        "\n",
        "    if 10 <= timestamp.hour <= 15:\n",
        "            is_peak.append(1)\n",
        "    else:\n",
        "        is_peak.append(0)\n",
        "    wd = timestamp.weekday()\n",
        "    weekdays.append(wd)\n",
        "    if wd in [5, 6]:\n",
        "        is_weekend.append(1)\n",
        "    else:\n",
        "        is_weekend.append(0)\n",
        "    hours.append(timestamp.hour)\n",
        "    months.append(timestamp.month)\n",
        "\n",
        "all_df['is_peak'] = is_peak\n",
        "all_df['is_weekend'] = is_weekend\n",
        "all_df['小时'] = hours\n",
        "all_df['周'] = weekdays\n",
        "all_df['月'] = months\n",
        "\n",
        "all_df = all_df[['省调负荷-日前(MW)', '时间戳', '火电竞价空间-日前(MW)', '新能源负荷-日前(MW)', '统一出清价格-日前(元/MWh)', '小时', '周', '月', 'is_peak', 'is_weekend']]\n",
        "\n",
        "# 为了绘图正确显示文字，全部采用英文字段名\n",
        "columns = ['dispatch load', 'timestamp', 'bid space', 'new energy load', 'price', 'hour', 'weekday', 'month', 'is peak', 'is weekend']\n",
        "all_df.columns = columns\n",
        "all_df.set_index('timestamp', inplace=True)\n",
        "all_df.head()\n"
      ],
      "metadata": {
        "id": "lK73zUJSZUUu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4、建模\n",
        "\n",
        "先定义一些用于评估、可视化预测结果的功能函数"
      ],
      "metadata": {
        "id": "D6Q9xTQ9ZsJX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compare_plot(y_true, y_pred, start_index=None, end_index=None):\n",
        "    start, end = start_index, end_index\n",
        "    if start is None:\n",
        "        start = 0\n",
        "    else:\n",
        "        start *= 96\n",
        "    if end is None:\n",
        "        end = -1\n",
        "    else:\n",
        "        end *= 96\n",
        "    fig, ax = plt.subplots(figsize=(30, 12))\n",
        "    ax.set_xlabel('Time', fontsize=16)\n",
        "    ax.plot(y_true[start: end], label='true value')\n",
        "    ax.plot(y_pred[start: end], label='predict value', linestyle='-', linewidth=1)\n",
        "\n",
        "    ax.legend()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def post_process(y_pred):\n",
        "    ret = []\n",
        "    for i in y_pred:\n",
        "        if i < 0:\n",
        "            ret.append(0)\n",
        "        elif i > 1500:\n",
        "            ret.append(1500)\n",
        "        else:\n",
        "            ret.append(i)\n",
        "    return ret\n",
        "\n",
        "\n",
        "def filtered_mape(y_true: list, y_pred: list):\n",
        "    \"\"\"为了使mape的值更加合理，过滤掉其中的0值\"\"\"\n",
        "    y_true_filtered, y_pred_filtered = [], []\n",
        "    for i in range(len(y_true)):\n",
        "        if y_true[i] != 0:\n",
        "            y_true_filtered.append(y_true[i])\n",
        "            y_pred_filtered.append(y_pred[i])\n",
        "            \n",
        "    return mean_absolute_percentage_error(y_true_filtered, y_pred_filtered)"
      ],
      "metadata": {
        "id": "XTB5istzUv8e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.1 机器学习模型"
      ],
      "metadata": {
        "id": "dzovoIq4Pf-l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.1.1 Random Forest"
      ],
      "metadata": {
        "id": "w5Z8BBufscD3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_size = int(all_df.shape[0] * 0.8)\n",
        "test_size = all_df.shape[0] - train_size\n",
        "print(f\"train data size: {train_size}\")\n",
        "print(f\"test data size: {test_size}\")\n",
        "\n",
        "train_data = all_df[:train_size]\n",
        "test_data = all_df[-test_size:]\n",
        "\n",
        "train_X = train_data[['dispatch load', 'bid space', 'new energy load', 'hour', 'weekday', 'month', 'is peak', 'is weekend']]\n",
        "train_y = train_data[['price']]\n",
        "test_X = test_data[['dispatch load', 'bid space', 'new energy load', 'hour', 'weekday', 'month', 'is peak', 'is weekend']]\n",
        "test_y = test_data[['price']]"
      ],
      "metadata": {
        "id": "2FIgPcr4sgLC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rf = RandomForestRegressor(n_estimators=10, criterion='absolute_error', random_state=123)\n",
        "rf.fit(train_X, train_y)"
      ],
      "metadata": {
        "id": "67U9Wme_5L-H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rf_pred = rf.predict(test_X)\n",
        "rf_pred = post_process(rf_pred)\n",
        "compare_plot(test_y.values, rf_pred, 0, 3)\n",
        "print('mape: ', filtered_mape(test_y.values, rf_pred))"
      ],
      "metadata": {
        "id": "M4Lz-zyw6Lqk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.1.2 XGBoost Normal"
      ],
      "metadata": {
        "id": "fDEVL0EhmYYo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model=xgb.XGBRegressor(max_depth=3, n_estimators=100, learning_rate=0.1)\n",
        "model.fit(train_X, train_y)"
      ],
      "metadata": {
        "id": "QtOyCE65M3J3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xgb_y_pred = model.predict(test_X)\n",
        "xgb_y_pred = post_process(xgb_y_pred)\n",
        "compare_plot(test_y.values, rf_pred, 0, 3)\n",
        "print('mape: ', filtered_mape(test_y.values, xgb_y_pred))"
      ],
      "metadata": {
        "id": "aDxVRVyeNeKG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.1.3 XGBoost\n",
        "\n",
        "价格的影响具有长期性。因此，在预测未来的价格时，需要考虑历史价格的影响。结合当前电力市场的现状，将每三天的价格数据看做一个待预测的点，这样预测得到的价格也包含了三天的值，可以供日前申报使用。"
      ],
      "metadata": {
        "id": "9ppXn0tiaXx_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_dataset(all_df, input_days, output_days=3,\n",
        "                   target_col='price'):\n",
        "    \"\"\"\n",
        "    从原始数据中处理得到数据集\n",
        "    all_df: 原始数据集\n",
        "    input_days: 作为特征的天数\n",
        "    output_days: 待预测的天数，默认为3\n",
        "    target_col: 目标列的名称\n",
        "    \"\"\"\n",
        "    in_window = input_days * 96\n",
        "    out_window = output_days * 96\n",
        "    in_data = []\n",
        "    out_data = []\n",
        "    for i in tqdm(range(len(all_df)-in_window-out_window)):\n",
        "        in_data.append(all_df.iloc[i: i+in_window, :].values)\n",
        "        out_data.append(all_df[target_col].iloc[i+in_window: i+in_window+out_window].values)\n",
        "    return np.array(in_data), np.array(out_data)"
      ],
      "metadata": {
        "id": "p-EVbmYUtjjR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X, y = create_dataset(all_df, 4)"
      ],
      "metadata": {
        "id": "3OOvHtGzwhnp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 按照7:1:2的比例划分为训练集、验证集和测试集\n",
        "data_len = X.shape[0]\n",
        "train_size = int(data_len * .7)\n",
        "val_size = int(data_len * .1)\n",
        "test_size = data_len - train_size - val_size\n",
        "\n",
        "train_X = X[:train_size]\n",
        "train_y = y[:train_size]\n",
        "val_X = X[train_size: train_size+val_size]\n",
        "val_y = y[train_size: train_size+val_size]\n",
        "test_X = X[train_size+val_size: train_size+val_size+test_size]\n",
        "test_y = y[train_size+val_size: train_size+val_size+test_size]"
      ],
      "metadata": {
        "id": "GKRv9KHuztzz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_X = train_X.reshape(-1, train_X.shape[1] * train_X.shape[2])\n",
        "val_X = val_X.reshape(-1, val_X.shape[1] * val_X.shape[2])\n",
        "test_X = test_X.reshape(-1, test_X.shape[1] * test_X.shape[2])"
      ],
      "metadata": {
        "id": "UzWJRTm91xDT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_X.shape)\n",
        "print(train_y.shape)"
      ],
      "metadata": {
        "id": "IUTIAb880qIm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_df['price'].iloc[0+96*4: 0+96*4+96*3]"
      ],
      "metadata": {
        "id": "rEBvDd27EtYK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_y[0]"
      ],
      "metadata": {
        "id": "p-yWaRIPEa_P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "param = {'eta': 0.03, 'max_depth': 180, \n",
        "         'subsample': 1, 'colsample_bytree': 0.95, \n",
        "         'alpha': 0.1, 'lambda': 0.15, 'gamma': 0.1,\n",
        "         'objective': 'reg:linear', 'eval_metric': 'rmse', \n",
        "         'silent': 1, 'min_child_weight': 0.1, 'n_jobs': -1}\n",
        "\n",
        "dtrain = xgb.DMatrix(train_X, train_y)\n",
        "dval = xgb.DMatrix(val_X, val_y)\n",
        "dtest = xgb.DMatrix(test_X)\n",
        "eval_list = [(dtrain, 'train'), (dval, 'eval')]"
      ],
      "metadata": {
        "id": "iUKS-kACadYS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xgb_model = xgb.train(param, dtrain, 180, eval_list, early_stopping_rounds=3)"
      ],
      "metadata": {
        "id": "MWH1YFlUjH02"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load a trained model\n",
        "# xgb_model = xgb.Booster()\n",
        "# xgb_model.load_model(\"/content/drive/MyDrive/models/xgb.model\")\n",
        "\n",
        "forecast = xgb_model.predict(dtest)\n",
        "forecast = post_process(forecast)\n",
        "compare_plot(test_y[0], forecast[:288], 0, 3)\n",
        "print('mape: ', filtered_mape(test_y.values, forecast))"
      ],
      "metadata": {
        "id": "Wsm_o1uCae-X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.2 深度学习模型\n",
        "\n",
        "基于pytorch的深度学习预测模型。\n"
      ],
      "metadata": {
        "id": "vuPKeERSPrFB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "导入所有的依赖："
      ],
      "metadata": {
        "id": "aFyUM9Ps_Ee4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "from torch.nn import Sequential, Conv1d, ReLU, Linear, LSTM\n",
        "from torch.utils.data import Dataset, DataLoader"
      ],
      "metadata": {
        "id": "r5djKz73UsMw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "定义一个用于Early Stopping的类，以防止过拟合。"
      ],
      "metadata": {
        "id": "DZKgPv1_UHkO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class EarlyStopping:\n",
        "    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n",
        "\n",
        "    def __init__(self, patience=7, verbose=False, delta=0, path='checkpoint.pt', trace_func=print):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            patience (int): How long to wait after last time validation loss improved.\n",
        "                            Default: 7\n",
        "            verbose (bool): If True, prints a message for each validation loss improvement. \n",
        "                            Default: False\n",
        "            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n",
        "                            Default: 0\n",
        "            path (str): Path for the checkpoint to be saved to.\n",
        "                            Default: 'checkpoint.pt'\n",
        "            trace_func (function): trace print function.\n",
        "                            Default: print            \n",
        "        \"\"\"\n",
        "        self.patience = patience\n",
        "        self.verbose = verbose\n",
        "        self.counter = 0\n",
        "        self.best_score = None\n",
        "        self.early_stop = False\n",
        "        self.val_loss_min = np.Inf\n",
        "        self.delta = delta\n",
        "        self.path = path\n",
        "        self.trace_func = trace_func\n",
        "    \n",
        "    def __call__(self, val_loss, model):\n",
        "\n",
        "        score = -val_loss\n",
        "\n",
        "        if self.best_score is None:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(val_loss, model)\n",
        "        elif score < self.best_score + self.delta:\n",
        "            self.counter += 1\n",
        "            self.trace_func(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True\n",
        "        else:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(val_loss, model)\n",
        "            self.counter = 0\n",
        "\n",
        "    def save_checkpoint(self, val_loss, model):\n",
        "        '''Saves model when validation loss decrease.'''\n",
        "        if self.verbose:\n",
        "            self.trace_func(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
        "        torch.save(model.state_dict(), self.path)\n",
        "        self.val_loss_min = val_loss"
      ],
      "metadata": {
        "id": "lsIvI_4TUJKR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "接下来需要对经过特征工程后的数据进行处理，包括标准化以及向量化："
      ],
      "metadata": {
        "id": "AqScRRxRYBW8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = all_df.drop('price', axis=1)\n",
        "y = all_df[['price']]\n",
        "\n",
        "scaler_X = MinMaxScaler(feature_range=(0, 1))\n",
        "scaler_y = MinMaxScaler(feature_range=(0, 1))\n",
        "\n",
        "scaler_X.fit(X)\n",
        "scaler_y.fit(y)\n",
        "\n",
        "X_norm = scaler_X.transform(X)\n",
        "y_norm = scaler_y.transform(y)\n",
        "\n",
        "ds_norm = np.concatenate((X_norm, y_norm), axis=1)"
      ],
      "metadata": {
        "id": "IhuC9WCQgW9W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "为了刻画历史对于未来价格的影响，需要将数据进行“序列化”：以过去w天的数据作为输入来预测未来d天的价格。在当前现货市场中，d最大取值只需要为3。又由于日前价格申报每天进行，因此，实际上只需要保证d为1时的准确率即可。\n",
        "\n",
        "为此，需要定义一个将数据序列化的函数："
      ],
      "metadata": {
        "id": "-pHJ_v-5gfVK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sequence_data(normed_data, input_days, output_days=3, use_out_features=False):\n",
        "    \"\"\"\n",
        "    将数据按照指定的窗口长度序列化\n",
        "\n",
        "    normed_data: 经过标准化的原始数据，形状为(m,n)，m为样本数，n为特征数+1，注意最后一列\n",
        "        为特征列\n",
        "    input_days: 作为特征的天数，即w\n",
        "    output_days: 待预测的天数，即d，默认为3\n",
        "    use_out_features: 是否使用待预测的时间戳范围内的特征作为输入\n",
        "    \"\"\"\n",
        "    in_window = input_days * 96\n",
        "    out_window = output_days * 96\n",
        "    in_data = []\n",
        "    out_data = []\n",
        "    for i in tqdm(range(len(normed_data)-in_window-out_window)):\n",
        "        if use_out_features:\n",
        "            in_data.append(normed_data[:, :][i: i+in_window+out_window, :])\n",
        "        else:\n",
        "            in_data.append(normed_data[:, :][i: i+in_window, :])\n",
        "        out_data.append(normed_data[:, -1][i+in_window: i+in_window+out_window])\n",
        "        \n",
        "    return np.array(in_data), np.array(out_data)"
      ],
      "metadata": {
        "id": "RkEUUVa8izkY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_seq, y_seq = sequence_data(ds_norm, 3, 1, True)\n",
        "print()\n",
        "print(f\"Samples' number of sequenced data: {X_seq.shape[0]}\")\n",
        "print(f\"Original feature number          : {X_seq.shape[-1]}\")\n",
        "print(f\"Input timestep length            : {X_seq.shape[1]}\")\n",
        "print(f\"Output timestep length           : {y_seq.shape[-1]}\")"
      ],
      "metadata": {
        "id": "0zA6-ukFlPtR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "接下来，划分训练集、验证集与测试集，并将它们转化为tensor。\n",
        "\n",
        "在划分时，需要注意：`train_data_size`与`eval_data_size`必须为浮点数；`test_data_size`可以为浮点数，也可以为整数。\n",
        "\n",
        "- `test_data_size`为浮点数时，必须保证$train\\_data\\_size+eval\\_data\\_size+test\\_data\\_size=1$，即按照指定的比例对数据进行划分。\n",
        "- `test_data_size`为整数时，表明将数据集的最后`test_data_size`个样本作为测试集，其余的样本按照比例被分为训练集和验证集，因此，须保证$train\\_data\\_size+eval\\_data\\_size=1$。"
      ],
      "metadata": {
        "id": "IE1D4iKhm_fv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # 定义部分 # #\n",
        "train_data_size = 0.75\n",
        "eval_data_size = 0.25\n",
        "test_data_size = 1\n",
        "# # # #\n",
        "\n",
        "assert isinstance(train_data_size, float)\n",
        "assert isinstance(eval_data_size, float)\n",
        "assert isinstance(test_data_size, (float, int))\n",
        "\n",
        "data_len = X_seq.shape[0]\n",
        "if isinstance(test_data_size, float):\n",
        "    assert train_data_size + eval_data_size + test_data_size == 1\n",
        "    train_data_size = int(data_len * train_data_size)\n",
        "    eval_data_size = int(data_len * eval_data_size)\n",
        "    test_data_size = data_len - train_data_size - eval_data_size\n",
        "else:\n",
        "    assert train_data_size + eval_data_size == 1\n",
        "    data_len -= test_data_size\n",
        "    train_data_size = int(data_len * train_data_size)\n",
        "    eval_data_size = data_len - train_data_size\n",
        "\n",
        "train_X = X_seq[:train_data_size]\n",
        "train_y = y_seq[:train_data_size]\n",
        "\n",
        "eval_X = X_seq[train_data_size: train_data_size+eval_data_size]\n",
        "eval_y = y_seq[train_data_size: train_data_size+eval_data_size]\n",
        "\n",
        "test_X = X_seq[train_data_size+eval_data_size: train_data_size+eval_data_size+test_data_size]\n",
        "test_y = y_seq[train_data_size+eval_data_size: train_data_size+eval_data_size+test_data_size]\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    train_X_tensor = torch.tensor(train_X).float().cuda()\n",
        "    train_y_tensor = torch.tensor(train_y).float().cuda()\n",
        "\n",
        "    eval_X_tensor = torch.tensor(eval_X).float().cuda()\n",
        "    eval_y_tensor = torch.tensor(eval_y).float().cuda()\n",
        "\n",
        "    test_X_tensor = torch.tensor(test_X).float().cuda()\n",
        "    test_y_tensor = torch.tensor(test_y).float().cuda()\n",
        "else:\n",
        "    train_X_tensor = torch.tensor(train_X).float()\n",
        "    train_y_tensor = torch.tensor(train_y).float()\n",
        "\n",
        "    eval_X_tensor = torch.tensor(eval_X).float()\n",
        "    eval_y_tensor = torch.tensor(eval_y).float()\n",
        "\n",
        "    test_X_tensor = torch.tensor(test_X).float()\n",
        "    test_y_tensor = torch.tensor(test_y).float()\n"
      ],
      "metadata": {
        "id": "GJFJ9peDnSrR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "原始数据处理完成之后，需要继承`Dataset`类来根据数据创建ds对象，以供模型使用："
      ],
      "metadata": {
        "id": "Dby5vn1Lr0Bm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MyDataset(Dataset):\n",
        "    def __init__(self, dataset_type,\n",
        "                 train_X=None, train_y=None,\n",
        "                 eval_X=None, eval_y=None,\n",
        "                 test_X=None):\n",
        "        self.dataset_type = dataset_type\n",
        "        self.train_X = train_X\n",
        "        self.train_y = train_y\n",
        "        self.eval_X = eval_X\n",
        "        self.eval_y = eval_y\n",
        "        self.test_X = test_X\n",
        "    \n",
        "    def __len__(self):\n",
        "        if self.dataset_type == 'train':\n",
        "            return self.train_X.shape[0]\n",
        "        elif self.dataset_type == 'eval':\n",
        "            return self.eval_X.shape[0]\n",
        "        else:\n",
        "            return self.test_X.shape[0]\n",
        "    \n",
        "    def __getitem__(self, i):\n",
        "        if self.dataset_type == 'train':\n",
        "            return self.train_X[i], self.train_y[i]\n",
        "        elif self.dataset_type == 'eval':\n",
        "            return self.eval_X[i], self.eval_y[i]\n",
        "        else:\n",
        "            return self.test_X[i]"
      ],
      "metadata": {
        "id": "DyO4suHz91kS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "最后，定义用于训练、评估以及预测的函数："
      ],
      "metadata": {
        "id": "N4JQlFJ7_3zJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(train_data_loader, model, loss_fn, optimizer, \n",
        "          eval_data_loader=None, early_stopping=None):\n",
        "    num_batches = len(train_data_loader)\n",
        "    total_loss = 0\n",
        "    loss_list = []\n",
        "    model.train()\n",
        "\n",
        "    for X, y in tqdm(train_data_loader):\n",
        "        output = model(X)\n",
        "        loss = loss_fn(output, y)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        step_loss = loss.item()\n",
        "        total_loss += step_loss\n",
        "        loss_list.append(step_loss)\n",
        "    avg_loss = total_loss / num_batches\n",
        "    print(f\"  Average train loss in current epoch: {avg_loss}\")\n",
        "    if eval_data_loader is not None:\n",
        "        print('  Evaluating...')\n",
        "        if evaluate(model, eval_data_loader, early_stopping) == -1:\n",
        "            return -1\n",
        "    return loss_list\n",
        "\n",
        "\n",
        "def evaluate(model, eval_data_loader, early_stopping):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        eval_loss = []\n",
        "        for X, y in eval_data_loader:\n",
        "            output = model(X)\n",
        "            loss = loss_fn(output, y)\n",
        "            eval_loss.append(loss.item())\n",
        "        print(f'  Evaluation loss: {np.average(eval_loss)}')\n",
        "        if early_stopping is not None:\n",
        "            early_stopping(np.average(eval_loss), model)\n",
        "            if early_stopping.early_stop:\n",
        "                print('Early stopped')\n",
        "                return -1\n",
        "        print()\n",
        "\n",
        "\n",
        "def do_train(model, loss_fn, optimizer, train_data_loader, epoches=10,\n",
        "             eval_data_loader=None, patience=None):\n",
        "    \"\"\"\n",
        "    执行训练。\n",
        "\n",
        "    model: 待训练的模型\n",
        "    loss_fn: 损失函数\n",
        "    optimizer: 优化器\n",
        "    train_data_loader: 封装的训练数据\n",
        "    epoches: 训练的轮数\n",
        "    eval_data_loader: 封装的验证数据\n",
        "    patience: 用于早停的耐心值\n",
        "    \"\"\"\n",
        "    if torch.cuda.is_available():\n",
        "        model.cuda()\n",
        "    \n",
        "    if eval_data_loader is None or patience is None:\n",
        "        early_stopping = None\n",
        "    else:\n",
        "        early_stopping = EarlyStopping(patience, verbose=True)\n",
        "    \n",
        "    train_losses = []\n",
        "\n",
        "    for epoch in range(epoches):\n",
        "        print(f\"epoch {epoch+1} in {epoches}:\")\n",
        "        epoch_loss = train(train_data_loader, model, loss_fn, optimizer, eval_data_loader, early_stopping)\n",
        "        if epoch_loss == -1:\n",
        "            break\n",
        "        train_losses.extend(epoch_loss)\n",
        "\n",
        "    return train_losses\n",
        "\n",
        "\n",
        "def do_predict(model, test_data_loader):\n",
        "    preds = []\n",
        "    with torch.no_grad():\n",
        "        for X in tqdm(test_data_loader):\n",
        "            pred = model(X)\n",
        "            if pred.is_cuda:\n",
        "                preds.append(pred.cpu().numpy())\n",
        "            else:\n",
        "                preds.append(pred.numpy())\n",
        "    return preds\n"
      ],
      "metadata": {
        "id": "scwNgcuV_9bz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.2.1 BiLSTM"
      ],
      "metadata": {
        "id": "fjEojn27GbMr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = MyDataset('train', train_X=train_X_tensor, train_y=train_y_tensor)\n",
        "eval_ds = MyDataset('eval', eval_X=eval_X_tensor, eval_y=eval_y_tensor)\n",
        "test_ds = MyDataset('test', test_X=test_X_tensor)\n",
        "\n",
        "train_data_loader = DataLoader(train_ds, batch_size=64, shuffle=True)\n",
        "eval_data_loader = DataLoader(eval_ds, batch_size=32)\n",
        "test_data_loader = DataLoader(test_ds, batch_size=1)"
      ],
      "metadata": {
        "id": "hwT4gTENXfZy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 定义模型架构\n",
        "class MyLSTM(torch.nn.Module):\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super().__init__()\n",
        "\n",
        "        self.lstm = LSTM(\n",
        "            input_size=input_size,\n",
        "            hidden_size=hidden_size,\n",
        "            batch_first=True,\n",
        "            bidirectional=True,\n",
        "            num_layers=4,\n",
        "            dropout=0.1\n",
        "        )\n",
        "        self.linear = torch.nn.Linear(in_features=hidden_size*2,\n",
        "                                      out_features=96)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        batch_size = x.shape[0]\n",
        "        o, _ = self.lstm(x)\n",
        "        out = self.linear(o[:, -1, :])\n",
        "        return out"
      ],
      "metadata": {
        "id": "YlmF_X7yG-SG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_size = train_X_tensor.shape[-1]\n",
        "model = MyLSTM(input_size, 81)\n",
        "loss_fn = torch.nn.MSELoss()\n",
        "optimizer = torch.optim.RMSprop(model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "otlyMoCM8KDt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loss = do_train(model, loss_fn, optimizer, train_data_loader, eval_data_loader=eval_data_loader, patience=3)"
      ],
      "metadata": {
        "id": "D9P7Pt9WLB4Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(torch.load('checkpoint.pt'))\n"
      ],
      "metadata": {
        "id": "75NlP6RMeFwC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred = do_predict(model, test_data_loader)[0]\n",
        "y_pred = scaler_y.inverse_transform(pred)[0]"
      ],
      "metadata": {
        "id": "O5y2vBXxY4lf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = post_process(y_pred)"
      ],
      "metadata": {
        "id": "dF6xl9Er85H5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if test_y_tensor[0].is_cuda:\n",
        "    y_true = test_y_tensor[0].cpu().reshape(-1, 1)\n",
        "else:\n",
        "    y_true = test_y_tensor[0].reshape(-1, 1)\n",
        "y_true = scaler_y.inverse_transform(y_true)"
      ],
      "metadata": {
        "id": "9p5GkplwZfdo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "compare_plot(y_true, y_pred)"
      ],
      "metadata": {
        "id": "qkA1u-RWOUjy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.2.2 将RF的预测值作为BiLSTM的一个特征"
      ],
      "metadata": {
        "id": "pBbdysRRShPk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "all_df.drop(all_df.index[-1], inplace=True)\n",
        "# 只保留最后三天的数据作为预测，其余数据为训练集，先训练一个xgb模型\n",
        "test_index = -(96 * 3)\n",
        "test_data = all_df[test_index:]\n",
        "train_data = all_df[:test_index]"
      ],
      "metadata": {
        "id": "IRexpioKuHeA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_X = train_data[['dispatch load', 'bid space', 'new energy load', 'hour', 'weekday', 'month', 'is peak', 'is weekend']]\n",
        "train_y = train_data[['price']]\n",
        "test_X = test_data[['dispatch load', 'bid space', 'new energy load', 'hour', 'weekday', 'month', 'is peak', 'is weekend']]\n",
        "test_y = test_data[['price']]\n",
        "\n",
        "rf = RandomForestRegressor(n_estimators=10, criterion='absolute_error', random_state=123)\n",
        "rf.fit(train_X, train_y)"
      ],
      "metadata": {
        "id": "6jq7lRM12VN0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_y_pred = rf.predict(train_X)\n",
        "xgb_y_pred = post_process(train_y_pred)"
      ],
      "metadata": {
        "id": "jtBDwVJw4BVt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "compare_plot(train_y.values, xgb_y_pred, 5, 7)"
      ],
      "metadata": {
        "id": "1GaJa5q44Q3z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_y_pred = rf.predict(test_X)\n",
        "test_y_pred = post_process(test_y_pred)\n",
        "compare_plot(test_y.values, test_y_pred)"
      ],
      "metadata": {
        "id": "lbflKhSh3nZ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 给原始序列增加一列，值为rf的预测价格\n",
        "all_df['rf_pred'] = np.concatenate((train_y_pred, test_y_pred)).reshape(1, -1)[0]\n",
        "# 接下来执行4.4部分的代码"
      ],
      "metadata": {
        "id": "e6r1Ku3u51GG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.2.3 CNN\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "> 当前效果较差\n"
      ],
      "metadata": {
        "id": "aixpfSn2AkO8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Flatten(torch.nn.Module):\n",
        "    def forward(self, x):\n",
        "        batch_size = x.shape[0]\n",
        "        return x.view(batch_size, -1)"
      ],
      "metadata": {
        "id": "y4sfhvjHK4So"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = MyDataset('train', train_X=train_X_tensor, train_y=train_y_tensor)\n",
        "eval_ds = MyDataset('eval', eval_X=eval_X_tensor, eval_y=eval_y_tensor)\n",
        "test_ds = MyDataset('test', test_X=test_X_tensor)\n",
        "\n",
        "train_data_loader = DataLoader(train_ds, batch_size=64, shuffle=True)\n",
        "eval_data_loader = DataLoader(eval_ds, batch_size=32)\n",
        "test_data_loader = DataLoader(test_ds, batch_size=1)"
      ],
      "metadata": {
        "id": "WoTkfymHENoe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "in_shape = train_X_tensor.shape\n",
        "in_channels = in_shape[1]  # input_channels的值为x的时间步长度\n",
        "\n",
        "cnn = torch.nn.Sequential(\n",
        "    Conv1d(in_channels=in_channels, out_channels=48, kernel_size=2, padding='same'),\n",
        "    ReLU(),\n",
        "    Conv1d(in_channels=48, out_channels=96, kernel_size=2, padding='same'),\n",
        "    Flatten(),\n",
        "    Linear(in_features=96*in_shape[-1], out_features=96),\n",
        ")"
      ],
      "metadata": {
        "id": "7kOTpFIOAoy5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.Adam(cnn.parameters(), lr=6e-3, amsgrad=True)\n",
        "loss_fn = torch.nn.MSELoss()"
      ],
      "metadata": {
        "id": "h_QSHwBDHRY8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loss = do_train(cnn, loss_fn, optimizer, train_data_loader, eval_data_loader=eval_data_loader, patience=3)"
      ],
      "metadata": {
        "id": "hUfrtdqjE4Nk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.load_state_dict(torch.load('checkpoint.pt'))"
      ],
      "metadata": {
        "id": "D2PHdn1qTfvv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y1 = do_predict(cnn, test_data_loader)[0]"
      ],
      "metadata": {
        "id": "V6-s3ZYQFW4H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaler_y.inverse_transform(y1)"
      ],
      "metadata": {
        "id": "BKsTrPx0UifK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "compare_plot(scaler_y.inverse_transform(test_y_tensor[0].reshape(-1,1)), scaler_y.inverse_transform(y1)[0])"
      ],
      "metadata": {
        "id": "OcEMywbVU5O9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}